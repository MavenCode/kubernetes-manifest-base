---
# Source: airflow/templates/webserver/webserver-deployment.yaml
# Licensed to the Apache Software Foundation (ASF) under one
# or more contributor license agreements.  See the NOTICE file
# distributed with this work for additional information
# regarding copyright ownership.  The ASF licenses this file
# to you under the Apache License, Version 2.0 (the
# "License"); you may not use this file except in compliance
# with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing,
# software distributed under the License is distributed on an
# "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
# KIND, either express or implied.  See the License for the
# specific language governing permissions and limitations
# under the License.

################################
## Airflow Webserver Deployment
#################################
kind: Deployment
apiVersion: apps/v1
metadata:
  name: airflow-webserver
  labels:
    tier: airflow
    component: webserver
    release: airflow
    chart: "airflow-1.2.0"
    heritage: Helm
spec:
  replicas: 1
  strategy:
    # Here we define the rolling update strategy
    # - maxSurge define how many pod we can add at a time
    # - maxUnavailable define how many pod can be unavailable
    #   during the rolling update
    # Setting maxUnavailable to 0 would make sure we have the appropriate
    # capacity during the rolling update.
    # You can also use percentage based value instead of integer.
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 0
  selector:
    matchLabels:
      tier: airflow
      component: webserver
      release: airflow
  template:
    metadata:
      labels:
        tier: airflow
        component: webserver
        release: airflow
      annotations:
        checksum/metadata-secret: dcbb26b06a9d686bf5fedceff6d4024447053fded58a37271cdfef14f8c8c800
        checksum/pgbouncer-config-secret: da52bd1edfe820f0ddfacdebb20a4cc6407d296ee45bcb500a6407e2261a5ba2
        checksum/webserver-secret-key: 170b1e24d24437dc5f796d43e23c8dddbbb91502e295989149a5ca92ca6cef11
        checksum/airflow-config: aea4f92ef86c687e5d97ba4bdb0b444a5ba44300ce2d568b1c1b554e87d799c8
        checksum/webserver-config: 4a2281a4e3ed0cc5e89f07aba3c1bb314ea51c17cb5d2b41e9b045054a6b5c72
        checksum/extra-configmaps: 2e44e493035e2f6a255d08f8104087ff10d30aef6f63176f1b18f75f73295598
        checksum/extra-secrets: bb91ef06ddc31c0c5a29973832163d8b0b597812a793ef911d33b622bc9d1655
    spec:
      serviceAccountName: airflow-webserver
      nodeSelector:
        {}
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - podAffinityTerm:
              labelSelector:
                matchLabels:
                  component: webserver
              topologyKey: kubernetes.io/hostname
            weight: 100
      tolerations:
        []
      restartPolicy: Always
      securityContext:
        runAsUser: 50000
        fsGroup: 0
      initContainers:
        - name: wait-for-airflow-migrations
          resources:
            {}
          image: apache/airflow:2.1.4
          imagePullPolicy: IfNotPresent
          args:          
            
            - python
            - -c
            - |
                  import airflow
                  import logging
                  import os
                  import time
          
                  from alembic.config import Config
                  from alembic.runtime.migration import MigrationContext
                  from alembic.script import ScriptDirectory
          
                  from airflow import settings
          
                  package_dir = os.path.abspath(os.path.dirname(airflow.__file__))
                  directory = os.path.join(package_dir, 'migrations')
                  config = Config(os.path.join(package_dir, 'alembic.ini'))
                  config.set_main_option('script_location', directory)
                  config.set_main_option('sqlalchemy.url', settings.SQL_ALCHEMY_CONN.replace('%', '%%'))
                  script_ = ScriptDirectory.from_config(config)
          
                  timeout=60
          
                  with settings.engine.connect() as connection:
                      context = MigrationContext.configure(connection)
                      ticker = 0
                      while True:
                          source_heads = set(script_.get_heads())
          
                          db_heads = set(context.get_current_heads())
                          if source_heads == db_heads:
                              break
          
                          if ticker >= timeout:
                              raise TimeoutError("There are still unapplied migrations after {} seconds.".format(ticker))
                          ticker += 1
                          time.sleep(1)
                          logging.info('Waiting for migrations... %s second(s)', ticker)
          envFrom:          
            []
          env:          
            # Dynamically created environment variables
            # Dynamically created secret envs
            - name: AIRFLOW_CONN_AWS
              valueFrom:
                secretKeyRef:
                  name: my-airflow-connections
                  key: AIRFLOW_CONN_AWS
            # Extra env          
            # Hard Coded Airflow Envs
            - name: AIRFLOW__CORE__FERNET_KEY
              valueFrom:
                secretKeyRef:
                  name: airflow-fernet-key
                  key: fernet-key
            - name: AIRFLOW__CORE__SQL_ALCHEMY_CONN
              valueFrom:
                secretKeyRef:
                  name: airflow-airflow-metadata
                  key: connection
            - name: AIRFLOW_CONN_AIRFLOW_DB
              valueFrom:
                secretKeyRef:
                  name: airflow-airflow-metadata
                  key: connection
            - name: AIRFLOW__WEBSERVER__SECRET_KEY
              valueFrom:
                secretKeyRef:
                  name: airflow-webserver-secret-key
                  key: webserver-secret-key
            - name: AIRFLOW__CELERY__CELERY_RESULT_BACKEND
              valueFrom:
                secretKeyRef:
                  name: airflow-airflow-result-backend
                  key: connection
            - name: AIRFLOW__CELERY__RESULT_BACKEND
              valueFrom:
                secretKeyRef:
                  name: airflow-airflow-result-backend
                  key: connection
            - name: AIRFLOW__CELERY__BROKER_URL
              valueFrom:
                secretKeyRef:
                  name: airflow-broker-url
                  key: connection
      containers:
        - name: webserver
          image: apache/airflow:2.1.4
          imagePullPolicy: IfNotPresent
          args: 
            - bash
            - -c
            - exec airflow webserver
          resources:
            {}
          volumeMounts:
            - name: config
              mountPath: "/opt/airflow/airflow.cfg"
              subPath: airflow.cfg
              readOnly: true
            - name: config
              mountPath: "/opt/airflow/config/airflow_local_settings.py"
              subPath: airflow_local_settings.py
              readOnly: true
          ports:
            - name: airflow-ui
              containerPort: 8080
          livenessProbe:
            httpGet:
              path: /health
              port: 8080
            initialDelaySeconds: 15
            timeoutSeconds: 30
            failureThreshold: 20
            periodSeconds: 5
          readinessProbe:
            httpGet:
              path: /health
              port: 8080
            initialDelaySeconds: 15
            timeoutSeconds: 30
            failureThreshold: 20
            periodSeconds: 5
          envFrom:          
            []
          env:          
            # Dynamically created environment variables
            # Dynamically created secret envs
            - name: AIRFLOW_CONN_AWS
              valueFrom:
                secretKeyRef:
                  name: my-airflow-connections
                  key: AIRFLOW_CONN_AWS
            # Extra env          
            # Hard Coded Airflow Envs
            - name: AIRFLOW__CORE__FERNET_KEY
              valueFrom:
                secretKeyRef:
                  name: airflow-fernet-key
                  key: fernet-key
            - name: AIRFLOW__CORE__SQL_ALCHEMY_CONN
              valueFrom:
                secretKeyRef:
                  name: airflow-airflow-metadata
                  key: connection
            - name: AIRFLOW_CONN_AIRFLOW_DB
              valueFrom:
                secretKeyRef:
                  name: airflow-airflow-metadata
                  key: connection
            - name: AIRFLOW__WEBSERVER__SECRET_KEY
              valueFrom:
                secretKeyRef:
                  name: airflow-webserver-secret-key
                  key: webserver-secret-key
            - name: AIRFLOW__CELERY__CELERY_RESULT_BACKEND
              valueFrom:
                secretKeyRef:
                  name: airflow-airflow-result-backend
                  key: connection
            - name: AIRFLOW__CELERY__RESULT_BACKEND
              valueFrom:
                secretKeyRef:
                  name: airflow-airflow-result-backend
                  key: connection
            - name: AIRFLOW__CELERY__BROKER_URL
              valueFrom:
                secretKeyRef:
                  name: airflow-broker-url
                  key: connection
      volumes:
        - name: config
          configMap:
            name: airflow-airflow-config
